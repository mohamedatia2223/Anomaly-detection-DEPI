# Multimodal AI Anomaly Detector

### Detect anomalies in **Text**, **Images**, and **Network Packets** using Machine Learning and Deep Learning

---

## Project Overview

The **Multimodal AI Anomaly Detector** is a unified system designed to detect **anomalies across multiple data types** â€” textual, visual, and network â€” using advanced AI models.

Originally developed as part of an **anomaly detection project**, this tool extends the concept beyond traditional network security to include **linguistic and visual anomalies**, making it a versatile system capable of identifying **AI-generated or abnormal content** across different modalities.

The app uses:

* **Text Anomaly Detection** â€” Detects unusual or AI-generated language using a fine-tuned **BERT model**.
* **Image Anomaly Detection** â€” Identifies AI-generated images using a **ConvNeXt classifier**.
* **Network Anomaly Detection** â€” Detects malicious or abnormal packet behavior using a **Sparse Autoencoder** trained on the **UNSW-NB15 dataset**.

---

## Key Features

* **Website Analysis:** Extracts and analyzes text and image data from any website to detect anomalies.
* **Text Detector:** Determines whether a piece of text is AI-generated or written by a human.
* **Image Detector:** Identifies whether an image is synthetic (AI-generated) or real.
* **Network Packet Detector:** Detects suspicious or anomalous network activity using reconstruction errors.
* **Unified Anomaly Framework:** Combines three AI domains â€” NLP, Computer Vision, and Cybersecurity â€” into a single pipeline.

---

## Project Architecture

```
Multimodal-AI-Anomaly-Detector/
â”‚   .gitignore
â”‚   environment.yml
â”‚   README.md
â”‚   requirements.txt
â”‚   setup.py
â”‚
â”œâ”€â”€â”€data
â”‚   â”œâ”€â”€â”€AI vs Human Text
â”‚   â”‚       ---.txt
â”‚   â”‚
â”‚   â”œâ”€â”€â”€AI vs Real images
â”‚   â”‚       --.txt
â”‚   â”‚
â”‚   â””â”€â”€â”€UNSW-NB15
â”‚       â”‚   --.txt
â”‚       â”‚
â”‚       â””â”€â”€â”€processed
â”‚               feature_columns.npy
â”‚               labels.npy
â”‚               scaler.pkl
â”‚               threshold.npy
â”‚
â”œâ”€â”€â”€docs
â”‚   â”œâ”€â”€â”€AI vs Real images
â”‚   â”‚       AI_vs_Human_Image_Detection_Report.docx
â”‚   â”‚
â”‚   â”œâ”€â”€â”€AI vs Real Text
â”‚   â”‚       Human_vs_AI_Text_Detection_Report.docx
â”‚   â”‚
â”‚   â””â”€â”€â”€UNSW-NB15
â”‚           Autoencoder_UNSW_Report.docx
â”‚
â”œâ”€â”€â”€notebooks
â”‚   â”œâ”€â”€â”€AI vs Human Text
â”‚   â”‚       human_vs_ai_text_detection.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€â”€AI vs Real images
â”‚   â”‚       convnext-classifier.ipynb
â”‚   â”‚
â”‚   â””â”€â”€â”€UNSW-NB15
â”‚           01_exploration.ipynb
â”‚           02_preprocessing.ipynb
â”‚           03_training.ipynb
â”‚           04_evaluation.ipynb
â”‚
â”œâ”€â”€â”€results
â”‚   â”œâ”€â”€â”€AI vs Human Text
â”‚   â”‚       Screenshot 2025-10-23 193442.png
â”‚   â”‚
â”‚   â””â”€â”€â”€UNSW-NB15
â”‚           Figure_1.png
â”‚           Figure_2.png
â”‚           Figure_3.png
â”‚
â””â”€â”€â”€src
    â”œâ”€â”€â”€app
    â”‚       app.py
    â”‚       style.css
    â”‚
    â””â”€â”€â”€models
            convnext_classifier.py
            human_vs_ai_text_detection.py
            sparse_autoencoder.py

```
## Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/mohamedatia2223/Anomaly-detection-DEPI
cd Multimodal-AI-Anomaly-Detector
```

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv venv
venv\\Scripts\\activate    # On Windows
source venv/bin/activate # On macOS/Linux
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Add Trained Models

Place your trained models in the following directories:

```
models/
 â”œâ”€â”€ AI vs Real Text/bert_model/
 â”œâ”€â”€ AI vs Real Images/convnext_ai_vs_human.pth
 â””â”€â”€ UNSW-NB15/autoencoder_full_model.h5
```

---

## â–¶ï¸ Run the Application

```bash
streamlit run src/app/app.py
```

Once launched, the interface allows you to:

* ğŸŒ Enter a website URL for text, image and packets anomaly detection
* ğŸ“ Paste text directly into the input box
* ğŸ–¼ï¸ Upload an image file
* ğŸ“¡ Upload a packet CSV file

---

## ğŸ§  Models Used

| Modality            | Model              | Framework              | Task                        |
| ------------------- | ------------------ | ---------------------- | --------------------------- |
| **Network Packets** | Sparse Autoencoder | TensorFlow/Keras       | Detect network anomalies    |
| **Text**            | Bert + OneClassSVM | PyTorch                | Detect linguistic anomalies |
| **Image**           | ConvNeXt           | PyTorch                | Detect visual anomalies     |
ConvNeXt
---

## ğŸ¨ User Interface

The web app uses **Streamlit** with a custom **dark-themed UI** styled via `style.css`, including:

* Glowing gradient buttons
* Rounded analysis cards
* Clean layout for multimodal analysis

---

## ğŸ§¾ Example Output

* **Text:** â€œAI-generatedâ€ if the text shows synthetic patterns
* **Image:** â€œHumanâ€ or â€œAI-generatedâ€ based on classification
* **Packets:** â€œAnomalousâ€ if reconstruction MSE < 0.25

---
